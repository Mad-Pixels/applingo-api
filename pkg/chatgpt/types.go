package chatgpt

import (
	"fmt"

	"github.com/Mad-Pixels/applingo-api/pkg/serializer"
	"github.com/pkg/errors"
)

const (
	defaultOpenAIURL   = "https://api.openai.com/v1/chat/completions"
	defaultTemperature = 0.7
)

var (
	// ErrEmptyResponse is returned when the API returns an empty response.
	ErrEmptyResponse = errors.New("empty response from API")
	// ErrEmptyModel is returned when the Request.Model field is empty.
	ErrEmptyModel = errors.New("model cannot be empty")
	// ErrEmptyContent is returned when the Request.Messages slice is empty.
	ErrEmptyContent = errors.New("content cannot be empty")
)

// OpenAIModel represents the model type for the OpenAI API.
type OpenAIModel string

// Supported OpenAI models.
const (
	GPT35Turbo OpenAIModel = "gpt-3.5-turbo"
	GPT40Mini  OpenAIModel = "gpt-4.0-mini"
	GPT4O      OpenAIModel = "gpt-4o"
)

// AvailableModels returns a slice of all supported OpenAI models.
func AvailableModels() []OpenAIModel {
	return []OpenAIModel{
		GPT35Turbo,
		GPT40Mini,
		GPT4O,
	}
}

// ParseModel converts a string to an OpenAIModel, returning error if invalid.
func ParseModel(name string) (OpenAIModel, error) {
	switch name {
	case string(GPT35Turbo):
		return GPT35Turbo, nil
	case string(GPT40Mini):
		return GPT40Mini, nil
	case string(GPT4O):
		return GPT4O, nil
	default:
		return "", fmt.Errorf("unknown model: %s", name)
	}
}

// APIErrorType represents the type of error returned by the OpenAI API.
type APIErrorType string

// Common API error types from OpenAI.
const (
	ErrorTypeInvalidRequest     APIErrorType = "invalid_request_error"
	ErrorTypeAuthentication     APIErrorType = "authentication_error"
	ErrorTypePermission         APIErrorType = "permission_error"
	ErrorTypeRateLimit          APIErrorType = "rate_limit_error"
	ErrorTypeQuotaExceeded      APIErrorType = "quota_exceeded_error"
	ErrorTypeInvalidAuth        APIErrorType = "invalid_auth_error"
	ErrorTypeServiceUnavailable APIErrorType = "service_unavailable_error"
	ErrorTypeModelOverloaded    APIErrorType = "model_overloaded_error"
	ErrorTypeContentFilter      APIErrorType = "content_filter_error"
)

// APIError represents an error returned by the OpenAI API.
type APIError struct {
	Type    APIErrorType `json:"type"`
	Message string       `json:"message"`
	Param   string       `json:"param,omitempty"`
	Code    string       `json:"code,omitempty"`
}

// Error returns a string representation of the APIError.
func (e APIError) Error() string {
	return fmt.Sprintf("API error: %s (type: %s, code: %s, param: %s)",
		e.Message, e.Type, e.Code, e.Param)
}

// ErrorResponse is the structure returned when the OpenAI API responds with an error.
type ErrorResponse struct {
	Error APIError `json:"error"`
}

// Message represents a single message in the conversation.
type Message struct {
	Role    string `json:"role"`    // Role indicates the sender of the message (e.g., "user" or "assistant").
	Content string `json:"content"` // Content is the actual message text.
}

// NewUserMessage creates a new message with the "user" role.
func NewUserMessage(content string) Message {
	return Message{
		Role:    "user",
		Content: content,
	}
}

// NewAssistantMessage creates a new message with the "assistant" role.
func NewAssistantMessage(content string) Message {
	return Message{
		Role:    "assistant",
		Content: content,
	}
}

// NewSystemMessage creates a new message with the "system" role.
func NewSystemMessage(content string) Message {
	return Message{
		Role:    "system",
		Content: content,
	}
}

// Choice represents one of the possible completions generated by the API.
type Choice struct {
	Message      Message `json:"message"`       // Message contains the generated message details.
	FinishReason string  `json:"finish_reason"` // FinishReason indicates why the generation stopped.
}

// Usage provides details about the token usage in the API call.
type Usage struct {
	PromptTokens     int `json:"prompt_tokens"`     // PromptTokens is the number of tokens in the input prompt.
	CompletionTokens int `json:"completion_tokens"` // CompletionTokens is the number of tokens generated in the output.
	TotalTokens      int `json:"total_tokens"`      // TotalTokens is the sum of prompt and completion tokens.
}

// Request represents the payload sent to the ChatGPT API.
type Request struct {
	Messages         []Message `json:"messages"`                    // Messages contains the conversation history.
	Model            string    `json:"model"`                       // Model specifies the ChatGPT model to be used.
	User             string    `json:"user,omitempty"`              // User is a unique identifier for the end-user, for OpenAI's monitoring.
	Temperature      float64   `json:"temperature,omitempty"`       // Temperature controls the randomness of the output.
	TopP             float64   `json:"top_p,omitempty"`             // TopP is an alternative to temperature for controlling randomness.
	PresencePenalty  float64   `json:"presence_penalty,omitempty"`  // PresencePenalty penalizes tokens based on whether they appear in the text so far.
	FrequencyPenalty float64   `json:"frequency_penalty,omitempty"` // FrequencyPenalty penalizes tokens based on their frequency in the text so far.
	MaxTokens        int       `json:"max_tokens,omitempty"`        // MaxTokens limits the tokens in the generated text.
}

// NewRequest creates a new Request with the specified model and messages.
func NewRequest(model OpenAIModel, messages []Message) *Request {
	return &Request{
		Model:       string(model),
		Messages:    messages,
		Temperature: defaultTemperature,
	}
}

// WithTemperature sets the temperature parameter for the request.
func (r *Request) WithTemperature(temperature float64) *Request {
	r.Temperature = temperature
	return r
}

// WithMaxTokens sets the max_tokens parameter for the request.
func (r *Request) WithMaxTokens(maxTokens int) *Request {
	r.MaxTokens = maxTokens
	return r
}

// Validate checks whether the Request contains all required fields.
// It returns an error if any required field is missing.
func (r *Request) Validate() error {
	if r.Model == "" {
		return ErrEmptyModel
	}
	if len(r.Messages) == 0 {
		return ErrEmptyContent
	}
	return nil
}

// Marshal converts the Request into its JSON representation.
func (r *Request) Marshal() ([]byte, error) {
	return serializer.MarshalJSON(r)
}

// Response represents the structure of the response received from the ChatGPT API.
type Response struct {
	ID      string   `json:"id"`      // ID is the unique identifier of the response.
	Object  string   `json:"object"`  // Object type (usually "chat.completion").
	Created int64    `json:"created"` // Created timestamp (in Unix time).
	Model   string   `json:"model"`   // Model used to generate the response.
	Choices []Choice `json:"choices"` // Choices contains the list of generated completions.
	Usage   Usage    `json:"usage"`   // Usage provides token usage information.
}

// GetResponseText returns the content of the first choice in the response.
func (r *Response) GetResponseText() string {
	if len(r.Choices) == 0 {
		return ""
	}
	return r.Choices[0].Message.Content
}

// Unmarshal parses the JSON-encoded data and stores the result in the Response struct.
func (r *Response) Unmarshal(data []byte) error {
	var errResp ErrorResponse
	if err := serializer.UnmarshalJSON(data, &errResp); err == nil && errResp.Error.Message != "" {
		return errResp.Error
	}
	return serializer.UnmarshalJSON(data, r)
}
